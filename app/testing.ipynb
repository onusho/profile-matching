{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import streamlit as st\n",
    "import _pickle as pickle\n",
    "from random import sample\n",
    "from PIL import Image\n",
    "from scipy.stats import halfnorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..\\\\data\\\\refined_profiles.pkl', 'rb') as fp:\n",
    "    df = pickle.load(fp)\n",
    "with open('..\\\\data\\\\refined_cluster.pkl', 'rb') as fp:\n",
    "    clustered_df = pickle.load(fp)\n",
    "with open('..\\\\data\\\\vectorized_refined.pkl', 'rb') as fp:\n",
    "    vect_df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load('..\\\\data\\\\refined_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(preference):\n",
    "    if isinstance(preference, list):\n",
    "        return ' '.join(preference)\n",
    "    else:\n",
    "        return preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df, columns):\n",
    "    # select the first column in database\n",
    "    column_name = columns[0]\n",
    "\n",
    "    # base condition, went through all columns\n",
    "    if column_name not in ['Bios', 'Movies','Religion', 'Music', 'Politics', 'Social Media', 'Sports']:\n",
    "        return df\n",
    "        \n",
    "    # they are stored as categorical values so can simply use .cat.codes\n",
    "    if column_name in ['Religion','Politics']:\n",
    "        df[column_name.lower()] = df[column_name].cat.codes\n",
    "        df = df.drop(column_name, axis=1)\n",
    "        return vectorize(df, df.columns)\n",
    "   \n",
    "    else:\n",
    "        vectorizer = CountVectorizer()\n",
    "        # first one Bios\n",
    "        vec = vectorizer.fit_transform(df[column_name])\n",
    "        # contains vectorized words\n",
    "        df_words = pd.DataFrame(vec.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "        new_df = pd.concat([df, df_words], axis=1)\n",
    "        # dropping original column\n",
    "        new_df = new_df.drop(column_name, axis=1)\n",
    "    \n",
    "        return vectorize(new_df, new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(df, input_df):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "    input_vect = pd.DataFrame(scaler.transform(input_df), \n",
    "                              index=input_df.index, \n",
    "                              columns=input_df.columns)\n",
    "    return input_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ten(cluster, vect_df, input_vect):\n",
    "    # filtering clustered data and appending new profile\n",
    "    des_cluster = vect_df[vect_df['Cluster #'] == cluster[0]].drop(columns=['Cluster #'])\n",
    "    des_cluster = pd.concat([des_cluster, input_vect], ignore_index=False, sort=False)\n",
    "    \n",
    "    # finding top 10 similar, correlated users in the cluster\n",
    "    user_n = input_vect.index[0]\n",
    "    corr = des_cluster.T.corrwith(des_cluster.log[user_n])\n",
    "    top_10_sim = corr.sort_values(ascending=False)[1:11]        # excluding the user\n",
    "    \n",
    "    top_10 = df.loc[top_10_sim.index]\n",
    "    top_10[top_10.columns[1:]] = top_10[top_10.columns[1:]].astype(int)\n",
    "    return top_10.astype('object')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_bios():\n",
    "    st.write('-' * 100)\n",
    "    st.text('Example Bios')\n",
    "    for i in sample(list(df.index), 3):\n",
    "        st.text(df['Bios'].loc[i])\n",
    "    st.write('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_categories():\n",
    "    with open('..\\\\data\\\\categories.pkl', 'rb') as f:\n",
    "        combined = pickle.load(f)\n",
    "    with open('..\\\\data\\\\probability.pkl', 'rb') as f:\n",
    "        p = pickle.load(f)\n",
    "    return combined, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frontend():\n",
    "    st.title('Vibe Check')\n",
    "    \n",
    "    st.header('Find Peeps with simillar Vibes')\n",
    "    st.write(\"using Machine Learning\")\n",
    "    image = Image.open('..\\\\data\\\\vibecheck.jpeg')\n",
    "    st.image(image, use_column_width=True)\n",
    "    \n",
    "    new_profile = pd.DataFrame(columns=df.columns, index=[df.index[-1] + 1])\n",
    "    new_profile['Bios'] = st.text_input(\"Enter a Bio for yourself\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
